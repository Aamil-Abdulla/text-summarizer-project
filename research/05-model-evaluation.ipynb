{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6f862eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Admin\\\\Desktop\\\\text-summarizer\\\\text-summarizer-project'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b77f8fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path        \n",
    "\n",
    "@dataclass\n",
    "class ModelEvaluationConfig:\n",
    "    root_dir: Path \n",
    "    model_path: Path\n",
    "    data_path: Path\n",
    "    metric_file_name: Path\n",
    "    tokenizer_path: Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2c69e1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-box in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (6.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7cd13af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"c:\\Users\\Admin\\Desktop\\text-summarizer\\text-summarizer-project\\src\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1f79e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_summarizer.constants import *\n",
    "from text_summarizer.utils.common import read_yaml, create_directories\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "20483371",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_path: Path):\n",
    "        if not config_path.exists():\n",
    "            raise FileNotFoundError(f\"Config file not found: {config_path}\")\n",
    "        with open(config_path, \"r\") as f:\n",
    "            self.config = yaml.safe_load(f)\n",
    "\n",
    "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
    "        cfg = self.config[\"model_evaluation\"]\n",
    "        return ModelEvaluationConfig(\n",
    "            root_dir=Path(cfg[\"root_dir\"]),\n",
    "            model_path=Path(cfg[\"model_path\"]),\n",
    "            tokenizer_path=Path(cfg[\"tokenizer_path\"]),\n",
    "            data_path=Path(cfg[\"data_path\"]),\n",
    "            metric_file_name=Path(cfg[\"metric_file_name\"])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04423f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63812c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7a513d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from text_summarizer.logging import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8df590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3cfa04bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (0.4.6)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from evaluate) (4.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from evaluate) (2.2.6)\n",
      "Requirement already satisfied: dill in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from evaluate) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from evaluate) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from evaluate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from evaluate) (0.70.18)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from evaluate) (0.36.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from datasets>=2.0.0->evaluate) (22.0.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from datasets>=2.0.0->evaluate) (0.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\envs\\ts\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e4f54b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5TokenizerFast\n",
    "from datasets import  Dataset , load_from_disk,load_dataset\n",
    "import torch\n",
    "from evaluate import load\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0b449251",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_path: Path):\n",
    "        if not config_path.exists():\n",
    "            raise FileNotFoundError(f\"Config file not found: {config_path}\")\n",
    "        with open(config_path, \"r\") as f:\n",
    "            self.config = yaml.safe_load(f)\n",
    "\n",
    "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
    "        cfg = self.config[\"model_evaluation\"]\n",
    "        return ModelEvaluationConfig(\n",
    "            root_dir=Path(cfg[\"root_dir\"]),\n",
    "            model_path=Path(cfg[\"model_path\"]),\n",
    "            tokenizer_path=Path(cfg[\"tokenizer_path\"]),\n",
    "            data_path=Path(cfg[\"data_path\"]),\n",
    "            metric_file_name=Path(cfg[\"metric_file_name\"])\n",
    "        )\n",
    "\n",
    "# =======================\n",
    "# MODEL EVALUATION CLASS\n",
    "# =======================\n",
    "class ModelEvaluation:\n",
    "    def __init__(self, config: ModelEvaluationConfig):\n",
    "        self.config = config\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        # Load model safely on Windows\n",
    "        model_dir = str(self.config.model_path.as_posix())\n",
    "        tokenizer_dir = str(self.config.tokenizer_path.as_posix())\n",
    "\n",
    "        logger.info(f\"Loading model from {model_dir}\")\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_dir).to(self.device)\n",
    "\n",
    "        logger.info(f\"Loading tokenizer from {tokenizer_dir}\")\n",
    "        self.tokenizer = T5TokenizerFast.from_pretrained(tokenizer_dir)\n",
    "\n",
    "    def generate_batch_sized_chunks(self, list_of_elements, batch_size):\n",
    "        for i in range(0, len(list_of_elements), batch_size):\n",
    "            yield list_of_elements[i:i + batch_size]\n",
    "\n",
    "    def calculate_metrics_on_test_ds(\n",
    "        self, dataset, metric, batch_size=4, column_text=\"article\", column_summary=\"highlights\"\n",
    "    ):\n",
    "        self.model.eval()\n",
    "        preds, refs = [], []\n",
    "\n",
    "        for batch in tqdm(self.generate_batch_sized_chunks(list(range(len(dataset))), batch_size)):\n",
    "            texts = [dataset[i][column_text] for i in batch]\n",
    "            summaries = [dataset[i][column_summary] for i in batch]\n",
    "\n",
    "            inputs = self.tokenizer(\n",
    "                texts,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=512\n",
    "            ).to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                summary_ids = self.model.generate(\n",
    "                    input_ids=inputs[\"input_ids\"],\n",
    "                    attention_mask=inputs[\"attention_mask\"],\n",
    "                    max_length=150,\n",
    "                    num_beams=2,\n",
    "                    early_stopping=True\n",
    "                )\n",
    "\n",
    "            decoded_preds = self.tokenizer.batch_decode(summary_ids, skip_special_tokens=True)\n",
    "            preds.extend(decoded_preds)\n",
    "            refs.extend(summaries)\n",
    "\n",
    "        return metric.compute(predictions=preds, references=refs)\n",
    "\n",
    "    def evaluate(self):\n",
    "        logger.info(\"Loading ROUGE metric\")\n",
    "        metric = load(\"rouge\")\n",
    "\n",
    "        logger.info(f\"Loading test dataset from {self.config.data_path}\")\n",
    "        test_dataset = load_from_disk(str(self.config.data_path.as_posix()))['test']\n",
    "\n",
    "        logger.info(\"Calculating metrics on test dataset\")\n",
    "        results = self.calculate_metrics_on_test_ds(test_dataset, metric)\n",
    "\n",
    "        logger.info(f\"Saving metrics to {self.config.metric_file_name}\")\n",
    "        df = pd.DataFrame([results])\n",
    "        df.to_csv(self.config.metric_file_name, index=False)\n",
    "        logger.info(\"Evaluation complete!\")\n",
    "\n",
    "# =======================\n",
    "# USAGE\n",
    "# =======================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c65da0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"c:\\Users\\Admin\\Desktop\\text-summarizer\\text-summarizer-project\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab8fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8dc2fd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-03 18:27:56,015 - INFO - 437885248 - Loading model from artifacts/model_trainer/t5-summarizer\n",
      "2025-12-03 18:27:56,822 - INFO - 437885248 - Loading tokenizer from artifacts/model_trainer/tokenizer\n",
      "2025-12-03 18:27:57,037 - INFO - 437885248 - Loading ROUGE metric\n",
      "2025-12-03 18:28:02,160 - INFO - 437885248 - Loading test dataset from artifacts\\data_ingestion\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Directory artifacts/data_ingestion is neither a `Dataset` directory nor a `DatasetDict` directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m     evaluator\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[85], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m     eval_config \u001b[38;5;241m=\u001b[39m config_manager\u001b[38;5;241m.\u001b[39mget_model_evaluation_config()\n\u001b[0;32m      5\u001b[0m     evaluator \u001b[38;5;241m=\u001b[39m ModelEvaluation(eval_config)\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[83], line 78\u001b[0m, in \u001b[0;36mModelEvaluation.evaluate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     75\u001b[0m metric \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrouge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     77\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading test dataset from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdata_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 78\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_from_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_posix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     80\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating metrics on test dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     81\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_metrics_on_test_ds(test_dataset, metric)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\ts\\lib\\site-packages\\datasets\\load.py:1479\u001b[0m, in \u001b[0;36mload_from_disk\u001b[1;34m(dataset_path, keep_in_memory, storage_options)\u001b[0m\n\u001b[0;32m   1477\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict\u001b[38;5;241m.\u001b[39mload_from_disk(dataset_path, keep_in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory, storage_options\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1480\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is neither a `Dataset` directory nor a `DatasetDict` directory.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1481\u001b[0m     )\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Directory artifacts/data_ingestion is neither a `Dataset` directory nor a `DatasetDict` directory."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        config_manager = ConfigurationManager(Path(\"config/config.yaml\"))\n",
    "        eval_config = config_manager.get_model_evaluation_config()\n",
    "        evaluator = ModelEvaluation(eval_config)\n",
    "        evaluator.evaluate()\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f0b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ModelEvaluation:\n",
    "#     def __init__(self, config: ModelEvaluationConfig):\n",
    "#         self.config = config\n",
    "    \n",
    "#     def generate_batch_sized_chunks(self, list_of_elements, batch_size):\n",
    "#         for i in range(0, len(list_of_elements), batch_size):\n",
    "#             yield list_of_elements[i:i + batch_size]\n",
    "    \n",
    "#     def calculate_metrics_on_test_ds(\n",
    "#         self, dataset, metric, model, tokenizer,\n",
    "#         batch_size=4,\n",
    "#         device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "#         column_text=\"article\",\n",
    "#         column_summary=\"highlights\"\n",
    "#     ):\n",
    "#         logger.info(f\"Using device: {device}\")\n",
    "#         model.to(device)\n",
    "\n",
    "#         preds = []\n",
    "#         refs = []\n",
    "\n",
    "#         for batch in tqdm(self.generate_batch_sized_chunks(list(range(len(dataset))), batch_size)):\n",
    "#             texts = [dataset[i][column_text] for i in batch]\n",
    "#             summaries = [dataset[i][column_summary] for i in batch]\n",
    "\n",
    "#             inputs = tokenizer(\n",
    "#                 texts,\n",
    "#                 return_tensors=\"pt\",\n",
    "#                 padding=True,\n",
    "#                 truncation=True,\n",
    "#                 max_length=512\n",
    "#             ).to(device)\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 summary_ids = model.generate(\n",
    "#                     input_ids=inputs[\"input_ids\"],\n",
    "#                     attention_mask=inputs[\"attention_mask\"],\n",
    "#                     max_length=150,\n",
    "#                     num_beams=2,\n",
    "#                     early_stopping=True\n",
    "#                 )\n",
    "\n",
    "#             decoded_preds = tokenizer.batch_decode(summary_ids, skip_special_tokens=True)\n",
    "#             decoded_labels = summaries\n",
    "\n",
    "#             preds.extend(decoded_preds)\n",
    "#             refs.extend(decoded_labels)\n",
    "\n",
    "#         return metric.compute(predictions=preds, references=refs)\n",
    "    \n",
    "#     def evaluate(self):\n",
    "#         logger.info(\"Loading model and tokenizer\")\n",
    "\n",
    "#         # Fix Windows path issue\n",
    "#         model_path = str(self.config.model_path).replace(\"\\\\\", \"/\")\n",
    "#         tokenizer_path = str(self.config.tokenizer_path).replace(\"\\\\\", \"/\")\n",
    "\n",
    "#         model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "#         tokenizer = T5TokenizerFast.from_pretrained(tokenizer_path)\n",
    "\n",
    "#         logger.info(\"Loading ROUGE metric\")\n",
    "#         metric = load(\"rouge\")\n",
    "\n",
    "#         logger.info(\"Loading test dataset\")\n",
    "#         test_dataset = load_from_disk(self.config.data_path)['test']\n",
    "\n",
    "#         logger.info(\"Calculating metrics on test dataset\")\n",
    "#         results = self.calculate_metrics_on_test_ds(test_dataset, metric, model, tokenizer)\n",
    "\n",
    "#         logger.info(\"Saving metrics to CSV\")\n",
    "#         df = pd.DataFrame([results])\n",
    "#         df.to_csv(self.config.metric_file_name, index=False)\n",
    "\n",
    "#         logger.info(f\"Metrics saved to {self.config.metric_file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d8df39",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "YAML file not found: config/config.yaml",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 61\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 61\u001b[0m     config_manager \u001b[38;5;241m=\u001b[39m \u001b[43mConfigurationManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     eval_config \u001b[38;5;241m=\u001b[39m config_manager\u001b[38;5;241m.\u001b[39mget_model_evaluation_config()\n\u001b[0;32m     63\u001b[0m     evaluator \u001b[38;5;241m=\u001b[39m ModelEvaluation(config\u001b[38;5;241m=\u001b[39meval_config)\n",
      "Cell \u001b[1;32mIn[34], line 13\u001b[0m, in \u001b[0;36mConfigurationManager.__init__\u001b[1;34m(self, config_filepath)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config_filepath\u001b[38;5;241m=\u001b[39mCONFIG_FILE_PATH):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_filepath \u001b[38;5;241m=\u001b[39m config_filepath\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_yaml_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_filepath\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[34], line 18\u001b[0m, in \u001b[0;36mConfigurationManager.read_yaml_file\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_yaml_file\u001b[39m(path):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path):\n\u001b[1;32m---> 18\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYAML file not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m yaml\u001b[38;5;241m.\u001b[39msafe_load(file)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: YAML file not found: config/config.yaml"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import yaml\n",
    "# import torch\n",
    "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "# from pathlib import Path\n",
    "# from text_summarizer.logging import logger\n",
    "\n",
    "# CONFIG_FILE_PATH = \"config/config.yaml\"\n",
    "\n",
    "# class ConfigurationManager:\n",
    "#     def __init__(self, config_filepath=CONFIG_FILE_PATH):\n",
    "#         self.config_filepath = config_filepath\n",
    "#         self.config = self.read_yaml_file(self.config_filepath)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def read_yaml_file(path):\n",
    "#         if not os.path.exists(path):\n",
    "#             raise FileNotFoundError(f\"YAML file not found: {path}\")\n",
    "#         with open(path, \"r\") as file:\n",
    "#             return yaml.safe_load(file)\n",
    "\n",
    "#     def get_model_evaluation_config(self):\n",
    "#         try:\n",
    "#             return self.config[\"model_evaluation\"]\n",
    "#         except KeyError:\n",
    "#             raise KeyError(\"Missing 'model_evaluation' section in config.yaml\")\n",
    "\n",
    "# class ModelEvaluation:\n",
    "#     def __init__(self, config):\n",
    "#         self.config = config\n",
    "#         self.model_dir = Path(self.config[\"model_dir\"])\n",
    "#         self.tokenizer_dir = Path(self.config[\"tokenizer_dir\"])\n",
    "#         self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#         self._load_model_and_tokenizer()\n",
    "\n",
    "#     def _load_model_and_tokenizer(self):\n",
    "#         model_path = self.model_dir / \"model.safetensors\"\n",
    "#         if not model_path.exists():\n",
    "#             raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "#         if not self.tokenizer_dir.exists():\n",
    "#             raise FileNotFoundError(f\"Tokenizer folder not found: {self.tokenizer_dir}\")\n",
    "\n",
    "#         self.tokenizer = AutoTokenizer.from_pretrained(self.tokenizer_dir)\n",
    "#         self.model = AutoModelForSeq2SeqLM.from_pretrained(model_path, device_map=\"auto\")\n",
    "#         self.model.to(self.device)\n",
    "#         logger.info(f\"Model and tokenizer loaded from {self.model_dir} and {self.tokenizer_dir}\")\n",
    "\n",
    "#     def evaluate(self, input_texts):\n",
    "#         self.model.eval()\n",
    "#         results = []\n",
    "#         for text in input_texts:\n",
    "#             inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(self.device)\n",
    "#             with torch.no_grad():\n",
    "#                 summary_ids = self.model.generate(**inputs, max_length=150, num_beams=4)\n",
    "#                 summary = self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "#                 results.append(summary)\n",
    "#         return results\n",
    "\n",
    "# # Usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     config_manager = ConfigurationManager()\n",
    "#     eval_config = config_manager.get_model_evaluation_config()\n",
    "#     evaluator = ModelEvaluation(config=eval_config)\n",
    "\n",
    "#     sample_texts = [\n",
    "#         \"This is a long text that we want to summarize using our model.\"\n",
    "#     ]\n",
    "#     summaries = evaluator.evaluate(sample_texts)\n",
    "#     for i, summary in enumerate(summaries):\n",
    "#         print(f\"Original: {sample_texts[i]}\\nSummary: {summary}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5dadb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d71de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-03 16:58:36,585 - INFO - common - YAML file: C:\\Users\\Admin\\Desktop\\text-summarizer\\text-summarizer-project\\config\\config.yaml loaded successfully.\n",
      "2025-12-03 16:58:36,592 - INFO - common - YAML file: C:\\Users\\Admin\\Desktop\\text-summarizer\\text-summarizer-project\\config\\params.yaml loaded successfully.\n",
      "2025-12-03 16:58:36,594 - INFO - common - Directory created at: artifacts\n",
      "2025-12-03 16:58:36,600 - INFO - 3102288557 - Using device: cpu\n",
      "2025-12-03 16:58:36,602 - INFO - 3102288557 - Loading model and tokenizer\n"
     ]
    },
    {
     "ename": "HFValidationError",
     "evalue": "Repo id must use alphanumeric chars, '-', '_' or '.'. The name cannot start or end with '-' or '.' and the maximum length is 96: 'C:\\Users\\Admin\\Desktop\\text-summarizer\\text-summarizer-project\\research\\artifacts\\model_trainer\\t5-summarizer'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\ts\\lib\\site-packages\\transformers\\utils\\hub.py:479\u001b[0m, in \u001b[0;36mcached_files\u001b[1;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[1;32m--> 479\u001b[0m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\ts\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 106\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\ts\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[1;34m(repo_id)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m The name cannot start or end with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and the maximum length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    164\u001b[0m     )\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n",
      "\u001b[1;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars, '-', '_' or '.'. The name cannot start or end with '-' or '.' and the maximum length is 96: 'C:\\Users\\Admin\\Desktop\\text-summarizer\\text-summarizer-project\\research\\artifacts\\model_trainer\\t5-summarizer'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m     model_evaluator\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[32], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m     eval_config \u001b[38;5;241m=\u001b[39m config_manager\u001b[38;5;241m.\u001b[39mget_model_evaluation_config()\n\u001b[0;32m      5\u001b[0m     model_evaluator \u001b[38;5;241m=\u001b[39m ModelEvaluation(config\u001b[38;5;241m=\u001b[39meval_config)\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mmodel_evaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[31], line 100\u001b[0m, in \u001b[0;36mModelEvaluation.evaluate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     98\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading model and tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 100\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mT5ForConditionalGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m T5TokenizerFast\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtokenizer_path))\n\u001b[0;32m    103\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading ROUGE metric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\ts\\lib\\site-packages\\transformers\\modeling_utils.py:277\u001b[0m, in \u001b[0;36mrestore_default_dtype.<locals>._wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\ts\\lib\\site-packages\\transformers\\modeling_utils.py:4734\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   4731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4732\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m   4733\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[1;32m-> 4734\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4735\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4736\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4737\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4738\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4739\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4740\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4741\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4742\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4743\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4744\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4745\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4746\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4747\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4748\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m   4749\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\ts\\lib\\site-packages\\transformers\\utils\\hub.py:322\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcached_file\u001b[39m(\n\u001b[0;32m    265\u001b[0m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[0;32m    266\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    268\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    269\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m     file \u001b[38;5;241m=\u001b[39m cached_files(path_or_repo_id\u001b[38;5;241m=\u001b[39mpath_or_repo_id, filenames\u001b[38;5;241m=\u001b[39m[filename], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    323\u001b[0m     file \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\ts\\lib\\site-packages\\transformers\\utils\\hub.py:531\u001b[0m, in \u001b[0;36mcached_files\u001b[1;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPermissionError at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m when downloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck cache directory permissions. Common causes: 1) another user is downloading the same model (please wait); \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2) a previous download was canceled and the lock file needs manual removal.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;66;03m# Now we try to recover if we can find all files correctly in the cache\u001b[39;00m\n\u001b[1;32m--> 531\u001b[0m resolved_files \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    532\u001b[0m     _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision, repo_type)\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m full_filenames\n\u001b[0;32m    534\u001b[0m ]\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m resolved_files):\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resolved_files\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\ts\\lib\\site-packages\\transformers\\utils\\hub.py:532\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPermissionError at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m when downloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck cache directory permissions. Common causes: 1) another user is downloading the same model (please wait); \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2) a previous download was canceled and the lock file needs manual removal.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;66;03m# Now we try to recover if we can find all files correctly in the cache\u001b[39;00m\n\u001b[0;32m    531\u001b[0m resolved_files \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 532\u001b[0m     \u001b[43m_get_cache_file_to_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m full_filenames\n\u001b[0;32m    534\u001b[0m ]\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m resolved_files):\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resolved_files\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\ts\\lib\\site-packages\\transformers\\utils\\hub.py:143\u001b[0m, in \u001b[0;36m_get_cache_file_to_return\u001b[1;34m(path_or_repo_id, full_filename, cache_dir, revision, repo_type)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_cache_file_to_return\u001b[39m(\n\u001b[0;32m    136\u001b[0m     path_or_repo_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    137\u001b[0m     full_filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m ):\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# We try to see if we have a cached version (not up to date):\u001b[39;00m\n\u001b[1;32m--> 143\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mtry_to_load_from_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m resolved_file \u001b[38;5;241m!=\u001b[39m _CACHED_NO_EXIST:\n\u001b[0;32m    147\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\ts\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg_name, arg_value \u001b[38;5;129;01min\u001b[39;00m chain(\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mzip\u001b[39m(signature\u001b[38;5;241m.\u001b[39mparameters, args),  \u001b[38;5;66;03m# Args values\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mitems(),  \u001b[38;5;66;03m# Kwargs values\u001b[39;00m\n\u001b[0;32m    104\u001b[0m ):\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 106\u001b[0m         \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m         has_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\ts\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[1;34m(repo_id)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m     )\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m The name cannot start or end with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and the maximum length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    164\u001b[0m     )\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have -- or .. in repo_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars, '-', '_' or '.'. The name cannot start or end with '-' or '.' and the maximum length is 96: 'C:\\Users\\Admin\\Desktop\\text-summarizer\\text-summarizer-project\\research\\artifacts\\model_trainer\\t5-summarizer'."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a88367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2650efb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
